---
title: 'Classifying Forest Cover'
output:
  pdf_document:
    latex_engine: lualatex
    highlight: kate
    toc: true
  html_document:
    theme: flatly
    highlight: kate
    toc: true
    df_print: paged
---

```{css style, echo = FALSE}
a, a:hover {
  color: #DE3131;
}
code {
  color: #E3A80E;
}
```

```{r setup, include = FALSE}
library(knitr)
library(kableExtra)

# a prefix nulling hook.

# make sure to keep the default for normal processing.
default_output_hook <- knitr::knit_hooks$get('output')

# output hooks handle normal R console output.
knitr::knit_hooks$set(output = function(x, options) {
  
  # grab 'comment' setting
  comment <- knitr::opts_current$get('comment')
  
  # if NA, replace comment with ''
  if(is.na(comment)) comment <- ''
  
  # regex to logically detect ' *[#]' string in x (the output string)
  can_null <- grepl(paste0(comment, '\\s*\\[\\d+\\]'), 
                     x, perl = TRUE)
  
  # check if 'null_prefix' chunk option is set to TRUE
  do_null <- isTRUE(knitr::opts_current$get('null_prefix'))
  
  if(can_null && do_null) {
    
    # R print output aligns at the right brace, gather this value - 1
    align_index <- regexpr('\\]', x)[1] - 1
    
    # two cases: start or newline; can probably combine into one using refs...
    
    #start
    # start of string, any character matching align_index times followed by ]
    re <- paste0('^.{', align_index, '}\\]\\s?')
    rep <- comment
    x <- gsub(re, rep, x) # replace re with empty string in x
    
    # new line
    # new line, any character matching align_index times followed by ]
    re <- paste0('\\\n.{', align_index, '}\\]\\s?')
    rep <- paste0('\n', comment) # new line followed by comment
    x <- gsub(re, rep, x) # replace re with new line followed by comment
  }
  
  # still unsure what this does...
  default_output_hook(x, options)

})

#options(width = 105) # for HTML output only; too wide for pdf
knitr::opts_chunk$set(cache = TRUE,
                      comment = NA,
                      message = FALSE, 
                      warning = FALSE, 
                      error = FALSE,
                      background = '#B9B9B9', # for pdf only
                      fig.align = 'center',
                      null_prefix = TRUE)

options(width = 100) # increase print output width for skim/glimpse
```

# Description

Using 13 temporal and geographic variables, the goal of this project is to classify the type of tree cover in the Roosevelt National Forest of northern Colorado, just outside of Fort Collins. The forest consists of 6 wilderness areas that have, according to the [University of California, Irvine's project depository](https://archive.ics.uci.edu/ml/datasets/Covertype), experienced minimal human disturbances, leaving the tree cover to be the result of natural processes.

The Kaggle Competition based around this data asks four questions:

1. Can you build a model that predicts what types of trees grow in an area based on the surrounding characteristics?

2. What kinds of trees are most common in the Roosevelt National Forest?

3. Which tree types can grow in more diverse environments? 

4. Are there certain tree types that are sensitive to an environmental factor, such as elevation or soil type?

The 13 variables included in the dataset are:

* **Cover_Type**: One of seven types of tree cover found in the forest. In the data downloaded for the project, the observations are coded 1 through 7. We have renamed them for clarity. Observations are based on the primary cover type of 30m x 30m areas, as determined by the United States Forest Service. This is our response variable.

* **Wilderness_Area**: Of the six wilderness areas in the Roosevelt National Forest, four were used in this dataset. In the original dataset, these were one-hot encoded. We put them in long form for better visualisation and because most machine learning methods will automatically one-hot encode categorical variables for us.

* **Soil_Type**: 40 soil types were identified in the dataset and more detailed information regarding the types can be found at [https://www.kaggle.com/uciml/forest-cover-type-dataset](). Similar to `Wilderness_Area`, `Soil_Type` was originally one-hot encoded. 

* **Elevation**: The elevation of the observation in meters above sea level.

* **Aspect**: The aspect of the observation in degrees azimuth.

* **Slope**: The slope at which the observation is observed in degrees.

* **Hillshade_9am**: The amount of hillshade for the observation at 09:00 on the summer solstice. This is a value between 0 and 225.

* **Hillshade_Noon**: The amount of hillshade for the observation at 12:00 on the summer solstice. This is a value between 0 and 225.

* **Hillshade_3pm**: The amount of hillshade for the observation at 15:00 on the summer solstice. This is a value between 0 and 225.

* **Vertical_Distance_To_Hydrology**: Vertical distance to nearest water source in meters. Negative numbers indicate distance below a water source.

* **Horizontal_Distance_To_Hydrology**: Horizontal distance to nearest water source in meters.

* **Horizontal_Distance_To_Roadways**: Horizontal distance to nearest roadway in meters.

* **Horizontal_Distance_To_Fire_Points**: Horizontal distance to nearest wildfire ignition point in meters.

## Outline

1. We are going to begin by examining the structure of the data and manipulating it to serve our visualisation needs. This will include:
    + Checking for missing values and duplicates.
    + Converting the data into a tidy structure by putting the types of soil and wilderness areas into long form and converting categorical variables to factors.
    + Giving names to the `Wilderness_Area` and `Cover_Type` variables to replace the indicator values.
    + Reordering the data for convenience and clarity.
  
2. We will then visualise the data to give us a better idea of what variables might be good predictor variables.

3. Following visualisation, we will determine which predictor variables to use by running a basic random forest model and observing the variable importance values

4. We will then split the data with an 80/20 train/test split.

5. Three machine learning models will be built with a 3-fold (for the sake of time) cross validation for each. All models will be built using the `caret` package:
    + Random forest, using the `randomForest` package with all predictor variables
    + Two models using a subset the subset of predictor values  
      + kNN - k nearest neighbours from the `knn` package
      + Random forest, using the `randomForest` package
  
6. Lastly, we will test the models using our test dataset to make sure the models generalise well and choose the best performing model based on predictive accuracy.

## Packages

```{r packages, cache = FALSE}
library(tidyverse) # for data exploration and manipulation
library(skimr) # for useful and beautiful summary statistics
library(GGally) # for correlation testing
library(caret) # for machine learning
```
```{r skimr_settings, include = FALSE}
# skimr settings to reduce unnecessary summary statistics and fit to page width
skim_with(numeric = list(complete = NULL,
                         n = NULL,
                         missing = NULL))
```

# Data Exploration

## Data Summary

Let's begin by taking a look at structure of the data.

```{r read_data}
cov <- read_csv('covtype.csv')
glimpse(cov)
```

We should also check for duplicated rows and missing values before we go any further.

```{r duplicates/NAs/summary, paged.print = FALSE, cache = FALSE}
# test for duplicates; approximately 13.5 times faster than using base::duplicated
nrow(cov) - nrow(distinct(cov))

# test for missing data
any(is.na(cov))

# basic summary statistics
skim(cov)
```

Let's take a moment to familiarise ourselves with the summary of our data. Using the oft overlooked `skimr` package for beautiful summary statistics, we can see that this is a massive dataset with 581,012 observations and 55 variables, but we are lucky enough to not have any missing data or duplicates.

Since we are only using the dataset as a learning tool, we will take a small sample so that our visualisations and machine learning calls can run efficiently. As we will be trying to predict `Cover_Type` using the variables in the dataset, we will take an equal number of samples from each of the seven types of cover to avoid class imbalances.

Additionally, we see that the `Soil_Type*` and `Wilderness_Area*` variables can be gathered into a tidy format for better visualisation. The `Cover_Type` variable is the variable of interest, so we are going to move that to the front of the data for convenience. We are also going to rename the values in the `Cover_Type` and `Wilderness_Area` variables to show the actual name of the value, rather than an indicator value. The names can be found on the [Kaggle competition page](https://www.kaggle.com/uciml/forest-cover-type-dataset). Because they are categorical variables, we should convert the `Cover_Type`, `Soil_Type` and `Wilderness_Area` variables to factors.

We will leave the `Hillshade_*` values in wide form for the moment.

```{r tidy_data}
set.seed(1808)
cov_tidy <- (cov %>% 
  
  # take a subset of the overall data containing 1000 samples of each cover type
  group_by(Cover_Type) %>% 
  sample_n(size = 1000) %>% 
  ungroup() %>% 
  
  # tidy Wilderness_Area* data and rename values
  gather(Wilderness_Area, Wilderness_Value, Wilderness_Area1:Wilderness_Area4) %>% 
  filter(Wilderness_Value >= 1) %>% 
  select(-Wilderness_Value) %>% 
  mutate(Wilderness_Area = str_extract(Wilderness_Area, '\\d+'),
         Wilderness_Area = str_replace_all(Wilderness_Area, 
                                           c(`1` = 'Rawah',
                                             `2` = 'Neota',
                                             `3` = 'Comanche Peak',
                                             `4` = 'Cache la Poudre')),
         Wilderness_Area = as.factor(Wilderness_Area)) %>% 
  
  # tidy Soil_Type* data
  gather(Soil_Type, Soil_Value, Soil_Type1:Soil_Type40) %>% 
  filter(Soil_Value == 1) %>% 
  select(-Soil_Value) %>% 
  mutate(Soil_Type = as.factor(str_extract(Soil_Type, '\\d+'))) %>%
    
  # rename Cover_Type variables
  mutate(Cover_Type = str_replace_all(Cover_Type,
                                      c(`1` = 'Spruce/Fir',
                                        `2` = 'Lodgepole Pine',
                                        `3` = 'Ponderosa Pine',
                                        `4` = 'Cottonwood/Willow',
                                        `5` = 'Aspen',
                                        `6` = 'Douglas Fir',
                                        `7` = 'Krummholz')),
         Cover_Type = as.factor(Cover_Type)) %>% 
  
  # reorder columns for convenience 
  select(Cover_Type:Soil_Type, 
         Elevation:Slope, 
         Hillshade_9am:Hillshade_3pm,
         Vertical_Distance_To_Hydrology,
         Horizontal_Distance_To_Hydrology:Horizontal_Distance_To_Fire_Points))

glimpse(cov_tidy)
```

Now that we have a nice, tidy tibble, let's take another look at some summary statistics regarding our sample before we move on to crafting some visualisations.

```{r tidy_summary, paged.print = FALSE, fig.width = 10, cache = FALSE}
skim(cov_tidy)
```

A few take-aways from the summary statistics of our sample set:

* Our tidy data contains 1,000 samples of each `Cover_Type`. The original data was highly uneven in terms of this variable with Spruce/Fir and Lodgepole Pine types dominating the landscape.

* The `Wilderness_Area` numbers are much closer now as well, with the exception of the Neota region. This was the smallest of regions in terms of observations in the original data, but it was much closer to the Cache la Poudre region in terms of numbers than it is following our sampling.

* The numerical values in the tidy data are not centred or scaled. This is great for us when it comes to visualising the data, but as we plan on running a kNN model, we will need to remember to pre-process the data before running the model.

## Data Visualisation

### Soil Type

A good starting point is to see which type of cover grows in which type of soil. Different soil characteristics, such as porosity and acidity, are known to play a large role in determining what plants can grow in a particular area, and so `Soil_Type` is sure to be a good predictor variable. For the purpose of exploration, we aren't interested in specific values, but rather the variation of `Cover_Type` by `Soil_Type`.

```{r cover_by_soil}
palette <- c('#A969E9', '#92C628', '#E2E25C', 
             '#E25C5E', '#5CDEE2', '#F58403', '#5F65DE')

ggplot(cov_tidy, aes(x = Cover_Type, fill = Cover_Type)) +
  geom_bar() +
  facet_wrap(~reorder(Soil_Type, sort(as.integer(Soil_Type))), scales = 'free') +
  labs(fill = 'Cover Type', title = 'Cover Type by Soil Type') +
  scale_fill_manual(values = palette) +
  theme_minimal() +
  theme(legend.position = 'bottom',
        plot.title = element_text(hjust = 0.5),
        axis.title = element_blank(),
        axis.text = element_blank(),
        panel.grid = element_blank())
```

`Soil_Type`s 21, 25, 36 and 37 contain only a single cover type while others, such as 11 or 24, contain multiple. One thing to note is that there are several soil types where the only cover type is Krummholz. This is a type of cover that grows in harsh conditions, such as sub-alpine regions, where other plants are rare and soils may be poor in organic nutrients. Another point of interest is that Krummholz and Cottonwood/Willow covers share only one soil type: type 4. You may also have noticed that soil types 7, 8 and 15 are missing; we simply did not have any instances of these types in our sample. Let's look at the role of `Elevation` and see if this explains any of our findings.

### Elevation

Using violin plots (a combination of box plots and density plots), we can get a decent idea of how each cover type is distributed across our predictor variables.

```{r elevation_by_cover}
ggplot(cov_tidy, aes(x = Cover_Type, y = Elevation)) +
  geom_violin(aes(fill = Cover_Type)) + 
  geom_point(alpha = 0.01, size = 0.5) +
  stat_summary(fun.y = 'median', geom = 'point') +
  labs(x = 'Cover Type') +
  scale_fill_manual(values = palette) +
  theme_minimal() +
  theme(legend.position = 'none',
        axis.text.x = element_text(angle = 45,
                                   hjust = 1),
        panel.grid.major.x = element_blank())
```

As expected, Krummholz cover is found at very high elevations where other covers are rare. Not only do Krummholz and Cottonwood/Willow covers not share many of the same soil types, they aren't found within nearly 500 meters of elevation to each other.

The [UCI dataset page](https://archive.ics.uci.edu/ml/datasets/Covertype) explains that the Neota wilderness area has the highest mean elevation, followed closely by the Rawah and Comanche Peak areas. Looking at a map of the Roosevelt National Forest tells us that the Cache la Poudre area is the area surrounding the lower-lying Cache la Poudre river. With our previous figure showing that `Elevation` plays a role in determining cover type, we should expect to find a different composition of `Cover_Type` in this area.

```{r elevation_by_wilderness_area, fig.width = 9}
ggplot(cov_tidy, aes(x = Cover_Type, y = Elevation)) +
  geom_violin(aes(fill = Cover_Type)) + 
  geom_point(alpha = 0.08, size = 0.5) +
  stat_summary(aes(group = Cover_Type), 
               fun.y = 'median', 
               geom = 'point',
               show.legend = FALSE) +
  labs(x = 'Cover Type by Wilderness Area') +
  scale_fill_manual(name = 'Cover Type',
                    values = palette) +
  facet_grid(. ~ Wilderness_Area, scales = 'free_x', switch = 'x') +
  theme_minimal() +
  theme(legend.position = 'bottom',
        axis.text.x = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.spacing = unit(1, 'lines'))
```

Keeping in mind that we are only working with a sample of the overall data, we can see that Cottonwood/Willow trees are only found in the Cache la Poudre area and Krummholz trees are only found in the upper elevations of the other three areas. A bar plot gives a better look at the counts of `Cover_Type` by `Wilderness_Area`.

```{r cover_by_wilderness_area}
ggplot(cov_tidy, aes(x = Cover_Type, fill = Cover_Type)) +
  geom_bar() +
  facet_wrap(~Wilderness_Area) +
  labs(x = 'Cover Type by Wilderness Area', y = 'Count') +
  scale_fill_manual(name = 'Cover Type',
                    values = palette) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.spacing = unit(1, 'line'))
```

### Slope

`Slope` is another geographic variable that might play a role in determining the type of cover in an area. Steeper slopes likely feature higher water run-off and increased erosion, leading to the need for cover types with stronger root systems that might be more tolerant to these harsher conditions.

```{r cover_by_slope}
ggplot(cov_tidy, aes(x = Cover_Type, y = Slope, fill = Cover_Type)) +
  geom_violin() + 
  geom_jitter(alpha = 0.04, size = 0.4,
              width = 0, height = 0.5) +
  stat_summary(fun.y = 'median', geom = 'point') +
  labs(x = 'Cover Type') +
  scale_fill_manual(values = palette) +
  theme_minimal() +
  theme(legend.position = 'none',
        axis.text.x = element_text(angle = 45,
                                   hjust = 1),
        panel.grid.major.x = element_blank())
```

Within our sample, there doesn't seem to be much variation in terms of `Slope` when measured across `Cover_Type`. At most, there appears to be an 8 or 9 degree difference between the medians of the Ponderosa Pine and the Spruce/Fir types, but the ranges are highly similar for all covers. We can expect that slope may play a role, but it may not be as strong of an indicator as `Soil_Type` or `Elevation`.

### Aspect and Hillshade

The dataset also contains some temporal data in the form of hillshade index values measured throughout the day. These values can be plotted against the aspect values to give us an idea of how sunlight, direction and time influence `Cover_Type`.

```{r hillshade_aspect, fig.height = 10}
cov_tidy %>% 
  gather(Hillshade, Hillshade_Index, Hillshade_9am:Hillshade_3pm) %>% 
  mutate(Hillshade = factor(Hillshade, 
                            levels = c('Hillshade_9am', 
                                       'Hillshade_Noon',
                                       'Hillshade_3pm'),
                            labels = c('Hillshade 09:00',
                                       'Hillshade 12:00',
                                       'Hillshade 15:00'))) %>% 
  ggplot(aes(x = Hillshade_Index, y = Aspect, colour = Cover_Type)) +
  geom_point(alpha = 0.1) +
  facet_grid(Cover_Type ~ Hillshade) +
  labs(x = 'Hillshade Index') +
  scale_colour_manual(name = 'Cover Type',
                      values = palette) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme_minimal() +
  theme(legend.position = 'bottom',
        strip.text.y = element_blank(),
        panel.spacing = unit(1, 'line'))
```

Shade Index ~ Aspect figures can be difficult to read because of the shear number of points on the plot; each facet in the above graph contains 1000 points, many of which are overlapping. When we reduce the alpha levels so that the points are nearly transparent (changing the shape to something hollow could also be useful here) and view the figure on a large enough platform, some interesting patterns start to emerge. For example, Cottonwood/Willow cover mostly has aspects between 100 and 150 degrees azimuth, roughly facing east-southeast, creating a large amount of hillshade during the morning and much less during the afternoon. The violin plots below also bear this out.

```{r aspect_by_cover}
ggplot(cov_tidy, aes(x = Cover_Type, y = Aspect)) +
  geom_violin(aes(fill = Cover_Type)) +
  stat_summary(fun.y = 'median', geom = 'point') +
  geom_point(alpha = 0.1, size = 0.3) +
  scale_fill_manual(values = palette) +
  theme_minimal() +
  theme(legend.position = 'none',
        panel.grid.major.x = element_blank())
```

### Distance to Landmarks

The dataset contains four measures of distance to three type of landmarks: water sources, roadways and fire points.

* Distance to water sources could show the extent of a cover's dependence on water. Lands closer to a water source are likely to have soil which is more saturated than those far away.

* Distance to roadways might indicate how well a type of cover deals with human interference; conversely, it could just show that roadways are built in a certain area, i.e. in lower elevations.

* Distance to fire points can be seen as a metric of a cover type's ability to regrow following a forest fire; types of cover which can regrow quickly will take hold of a new area long before a slow-growing cover. 

```{r dist_to_landmarks, fig.height = 6, fig.width = 8}
cov_tidy %>% 
  gather(Measure, Distance, 
         Vertical_Distance_To_Hydrology:Horizontal_Distance_To_Fire_Points) %>% 
  mutate(Measure = factor(Measure, 
                          levels = c('Vertical_Distance_To_Hydrology',
                                     'Horizontal_Distance_To_Hydrology',
                                     'Horizontal_Distance_To_Roadways',
                                     'Horizontal_Distance_To_Fire_Points'),
                          labels = c('Vertical Distance to Hydrology',
                                     'Horizontal Distance to Hydrology',
                                     'Horizontal Distance to Roadways',
                                     'Horizontal Distance to Fire Points'))) %>% 
  ggplot(aes(x = Cover_Type, y = Distance, fill = Cover_Type)) +
  geom_violin() +
  geom_point(alpha = 0.01, size = 0.5) +
  stat_summary(fun.y = 'median', geom = 'point',
               show.legend = FALSE) +
  facet_wrap(~Measure, scales = 'free_y') +
  labs(x = NULL, y = 'Distance (m)') +
  scale_fill_manual(name = 'Cover Type',
                    values = palette) +
  theme_minimal() +
  theme(legend.position = 'bottom',
        axis.text.x = element_blank(),
        panel.spacing = unit(1, 'line'),
        panel.grid.major.x = element_blank())
```

With the exception of `Vertical_Distance_To_Hydrology`, there seems to be a good amount of variation between `Cover_Type`s for the distance measurements. `Vertical_Distance_To_Hydrology` is on the smallest scale by about 800 meters, and all of the medians are within about 50 meters of each other. There is some variation in the ranges for this measurement, but the other three metrics might prove better predictors of `Cover_Type`.

# Modelling

We should always consider correlations in the data. The `corrplot` function provides a succinct graph to visualise correlation between variables. Correlations are not necessarily bad, but we should be aware of them because they can impact certain machine learning models.

```{r pairplot, fig.height = 11, fig.width = 9}
ggpairs(cov_tidy, columns = 4:13, aes(colour = Cover_Type),
        diag = list(continuous = wrap('densityDiag', 
                                      alpha = 0.5)),
        lower = list(continuous = wrap('points', 
                                       alpha = 0.1))) +
  theme(legend.position = "none", 
        axis.text = element_blank(),
        panel.grid.major = element_blank(), 
        axis.ticks = element_blank(),
        panel.border = element_rect(linetype = "dashed", 
                                    colour = "black", 
                                    fill = NA)) 
```

For the most part, the data in our sample is uncorrelated with a few exceptions:
  
  * `Hillshade_9am` and `Hillshade_3pm` are negatively correlated and `Hillshade_Noon` and `Hillshade_3pm` are positively correlated. Interestingly, `Hillshade_9am` and `Hillshade_Noon` show virtually no correlation (-0.01).

* `Slope` and `Hillshade_Noon` are positively correlated.

* `Aspect` is also correlated with `Hillshade_9am` (negatively) and `Hillshade_3pm` (positively), which we would expect.

* Vertical and horizontal distances to hydrology are positively correlated.

Due to the nature of random variable selection and single variable splits with random forest models, correlated values aren't much of a concern. There is always a chance that the correlated values won't be chosen together for each decision, provided the mtry value is not too high and, even if the correlated values are chosen together, the splits are based only on one predictor variable.

Correlated values can pose a problem for kNN models, but we can deal with this by performing feature selection prior to building a kNN model. There are multiple ways we can do this, but we are going to run a simple PCA in order to select our features.

## Variable Selection

For variable selection we are using the a random forest method from the `randomForest` package with the importance parameter set to TRUE. Importance is determined by two metrics: mean decrease in accuracy and mean decrease in gini. We will select variables which have a mean decrease in accuracy greater than 0.10.

Additionally, we will use our tidied data as input into the random forest model because we have categorical variables which should be treated as such, rather than as the dummy variables in the raw data.

```{r feature_selection, fig.height = 7, fig.width = 8}
set.seed(1808)

vars <- randomForest::randomForest(Cover_Type ~ ., data = cov_tidy, 
                                      importance = TRUE)

vars$importance %>% 
  as_tibble(rownames = 'Variable') %>% 
  mutate(Variable = factor(Variable)) %>% 
  ggplot(aes(x = fct_reorder(Variable, MeanDecreaseAccuracy, .desc = TRUE), 
             y = MeanDecreaseAccuracy)) +
    geom_col() +
    geom_hline(yintercept = 0.10, colour = 'red') +
    labs(x = 'Variable', y = 'Mean Decrease in Accuracy') +
    theme_minimal() +
    theme(panel.grid.major.x = element_blank(),
          axis.text.x = element_text(angle = 45,
                                     hjust = 1))
```

Mean decrease in accuracy is a metric which measures how much the exclusion of a variable from a tree affected the ability for a tree to predict the correct outcome. In our example, when trees did not contain the `Elevation` variable, the accuracy of the tree was, on average across all cover types, 0.3597 lower than when Elevation was included in the tree. With our arbitrary cut-off of 0.10 `MeanDecreaseAccuracy`, we will be using the following variables to build our trees:

*`Elevation`

*`Soil_Type`

*`Wilderness_Area`

*`Horizontal_Distance_To_Roadways`

Keep in mind that using a method of feature selection might not return results that are logical in the eyes of a domain expert. I personally would think to include distances to hydrology and `Aspect` rather than the `Horizontal_Distance_To_Roadways`. There is likely some correlation between `Elevation` and `Horizontal_Distance_To_Roadways` which is making the latter seem more important than it really should be. However, this is an exercise in machine learning and not botany, so we are just going to go ahead with these four variables.

## Model Building {.tabset .tabset-fade}

Let's start building some models by splitting our data into training and test sets. We will use an 80/20 split.

```{r train_test_split}
set.seed(1808)

cov_tidy_train <- cov_tidy %>%
  sample_frac(0.8)

cov_tidy_test <- anti_join(cov_tidy, cov_tidy_train)
```

We can also build our `trainControl` now to ensure all models behave equally. We are going to use a simple 3-fold cross-validation to test for out-of-sample performance.

```{r cv_folds}
set.seed(1808)

# create 10 folds for cross-validation for accurate comparison across models
folds <- createFolds(y = cov_tidy_train$Cover_Type, 
                     k = 3,
                     returnTrain = TRUE)

control <- trainControl(method = 'cv', 
                        index = folds)
```

### Baseline Model

We are going to create a baseline model using all 12 of the predictor variables and a random forest model so that we can compare the effect of tweaking the parameters. For the sake of time, we are going to limit the number of trees created to 200 trees.
```{r baseline_model}
set.seed(1808)
mod_base <- train(x = cov_tidy_train[-1], 
                  y = cov_tidy_train$Cover_Type,
                  method = 'rf',
                  ntree = 200,
                  trControl = control)

mod_base
mean(predict(mod_base, cov_tidy_test) == cov_tidy_test$Cover_Type)
```
Our baseline model gives an in-sample accuracy of 0.8201781 and a predictive accuracy of 0.8385714. These are pretty good numbers for having done very little work aside from plugging the data into the machine learning function. Let's see how our other two models compare with these numbers.

### K Nearest Neighbours with Selected Variables

For our k-Nearest Neighbours model, we need to remember to pre-process the data by centring and scaling it. We can also select a range of values of k for our model to test. Here, we will use the square root of the number of rows of our training data +/- 10. 

```{r knn}
set.seed(1808)
mod_knn <- train(Cover_Type ~ ., 
                 data = cov_tidy_train %>% 
                          select(Cover_Type,
                                 Elevation,
                                 Soil_Type,
                                 Wilderness_Area,
                                 Horizontal_Distance_To_Roadways),
                 method = 'knn',
                 tuneGrid = expand.grid(k = (round(sqrt(nrow(cov_tidy_train))) - 10):
                                            (round(sqrt(nrow(cov_tidy_train))) + 10)),
                 preProcess = c('center', 'scale'),
                 trControl = control)

mod_knn
mean(predict(mod_knn, cov_tidy_test) == cov_tidy_test$Cover_Type)
```

Our basic knn model with preprocessing didn't do a great job at predicting forest cover. With an in-sample accuracy of 0.6435616 and a predicitve accuracy of 0.6714286, we are quite a bit below the predicitve capabilities of our baseline model.

Even though we took only a small sample of the overall dataset to build our model with, it doesn't make sense to allow for very low (< 10) values of k, as these values can simply be picking up noise rather than trends in our data. If we had chosen a very low value for k, the accuracy of our model would have been greater, but logically it does not make sense.

### Random Forest with Selected Variables

Our baseline model performs fairly well, but let's say we wanted to reduce the time it took to run because the full dataset contains over 500,000 rows or data, and we feel that there may be a few extraneous predictor variables. How would choosing only the four variables we earlier determined to be "important" as our predictor variables affect the overall accuracy of the model?
```{r rf}
set.seed(1808)
mod_rf <- train(x = cov_tidy_train %>% 
                      select(Elevation,
                             Soil_Type,
                             Wilderness_Area,
                             Horizontal_Distance_To_Roadways), 
                y = cov_tidy_train$Cover_Type,
                method = 'rf',
                ntree = 200,
                trControl = control)

mod_rf
mean(predict(mod_rf, cov_tidy_test) == cov_tidy_test$Cover_Type)
```
Compared to our knn model with selected features, our random forest model performed quite well. Removing all but four of the predictor variables still gives us a respectable 0.7549958 in-sample accuracy and a predictive accuracy of 0.78. 

## Model Selection

Now we can choose a model and it with our entire `cov_tidy` data and consider it to be in production, ready to predict on any new data we may feed to it. In fact, we have an abundance of this "new data" in the form of the data from the original data set that we did not use in our subset. However, I see no need to do this right now as we have already tested the models on data separate from the training data.

Let's declare the winner to be the random forest model with selected features as it has a respectable predictive accuracy, having only lost ~0.05 accuracy compared to the baseline model, while reducing the number of predictor variables from 12 to 4.

## Answering the Questions

We need to remember that the whole reason we performed this machine learning exercise was not to try and get the highest score, but to answer some important questions.

1. Can you build a model that predicts what types of trees grow in an area based on the surrounding characteristics?

Absolutely! While the baseline model proved to have the highest accuracy, the model where we removed all but four predictor variables did a pretty decent job at predicting the outcomes in the test data. This just goes to show that not all predictors should be treated equally and trusted blindly.

2. What kinds of tree covers are most common in the Roosevelt National Forest?

```{r question2, paged.print = FALSE, cache = FALSE}
cov %>% 
  mutate(Cover_Type = str_replace_all(Cover_Type,
                                      c(`1` = 'Spruce/Fir',
                                        `2` = 'Lodgepole Pine',
                                        `3` = 'Ponderosa Pine',
                                        `4` = 'Cottonwood/Willow',
                                        `5` = 'Aspen',
                                        `6` = 'Douglas Fir',
                                        `7` = 'Krummholz')),
         Cover_Type = as.factor(Cover_Type)) %>% 
  group_by(Cover_Type) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  knitr::kable(booktabs = TRUE, longtable = TRUE)
```
Lodgepole Pines and Spruce/Firs dominate the landscape in the Roosevelt National Forest. Machine learning methods can often run into issues when using training data that has large differences in the number of target classes. This was the reason we chose to build our model with 1000 samples of each type of cover.

3. Which tree types can grow in more diverse environments? 

This question can be interpreted in multiple ways: What tree covers can be found in all four wilderness areas? What tree covers can be found in most soil types, at the widest spread of elevation, etc. As such, we are going to ignore it.

4. Are there certain tree types that are sensitive to an environmental factor, such as elevation or soil type?

Of course there are! The whole point of our data visualisation earlier was to see if there were differences between the types of cover in terms of the predictor variables in the data set.